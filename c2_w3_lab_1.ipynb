{"metadata":{"accelerator":"GPU","colab":{"name":"C2_W3_Lab_1_transfer_learning.ipynb","private_outputs":true,"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C2/W3/ungraded_lab/C2_W3_Lab_1_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"53Pr0cX37buR"}},{"cell_type":"markdown","source":"I have run this notebook on Kaggle using GPU T4 x2 as Accelerator.","metadata":{}},{"cell_type":"code","source":"!python3 -m venv venv","metadata":{"execution":{"iopub.status.busy":"2024-07-26T12:17:38.345409Z","iopub.execute_input":"2024-07-26T12:17:38.346154Z","iopub.status.idle":"2024-07-26T12:17:43.421705Z","shell.execute_reply.started":"2024-07-26T12:17:38.346116Z","shell.execute_reply":"2024-07-26T12:17:43.420506Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!source ./venv/bin/activate","metadata":{"execution":{"iopub.status.busy":"2024-07-26T12:17:43.423704Z","iopub.execute_input":"2024-07-26T12:17:43.424018Z","iopub.status.idle":"2024-07-26T12:17:44.449545Z","shell.execute_reply.started":"2024-07-26T12:17:43.423989Z","shell.execute_reply":"2024-07-26T12:17:44.448352Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!python --version","metadata":{"execution":{"iopub.status.busy":"2024-07-26T12:17:44.451278Z","iopub.execute_input":"2024-07-26T12:17:44.452128Z","iopub.status.idle":"2024-07-26T12:17:45.444741Z","shell.execute_reply.started":"2024-07-26T12:17:44.452085Z","shell.execute_reply":"2024-07-26T12:17:45.443798Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Python 3.10.13\n","output_type":"stream"}]},{"cell_type":"code","source":"!python3 -m pip install --upgrade pip","metadata":{"execution":{"iopub.status.busy":"2024-07-26T12:17:47.481998Z","iopub.execute_input":"2024-07-26T12:17:47.482857Z","iopub.status.idle":"2024-07-26T12:18:14.612130Z","shell.execute_reply.started":"2024-07-26T12:17:47.482823Z","shell.execute_reply":"2024-07-26T12:18:14.611191Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.2)\nCollecting pip\n  Downloading pip-24.1.2-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-24.1.2-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.3.2\n    Uninstalling pip-23.3.2:\n      Successfully uninstalled pip-23.3.2\nSuccessfully installed pip-24.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tensorflow","metadata":{"execution":{"iopub.status.busy":"2024-07-26T12:18:14.614133Z","iopub.execute_input":"2024-07-26T12:18:14.614440Z","iopub.status.idle":"2024-07-26T12:18:22.521908Z","shell.execute_reply.started":"2024-07-26T12:18:14.614411Z","shell.execute_reply":"2024-07-26T12:18:22.520799Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.4.1\n    Uninstalling keras-3.4.1:\n      Successfully uninstalled keras-3.4.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Ungraded Lab: Transfer Learning\n\nIn this lab, you will see how you can use a pre-trained model to achieve good results even with a small training dataset. This is called _transfer learning_ and you do this by leveraging the trained layers of an existing model and adding your own layers to fit your application. For example, you can:\n\n1. just get the convolution layers of one model\n2. attach some dense layers onto it\n3. train just the dense network\n4. evaluate the results\n\nDoing this will allow you to save time building your application because you will essentially skip weeks of training time of very deep networks. You will just use the features it has learned and tweak it for your dataset. Let's see how these are done in the next sections.","metadata":{"id":"bT0to3TL2q7H"}},{"cell_type":"markdown","source":"**IMPORTANT NOTE:** This notebook is designed to run as a Colab. Running the notebook on your local machine might result in some of the code blocks throwing errors.","metadata":{"id":"Qvrr8pLRzJMV"}},{"cell_type":"markdown","source":"## Setup the pretrained model\n\nYou will need to prepare pretrained model and configure the layers that you need. For this exercise, you will use the convolution layers of the [InceptionV3](https://arxiv.org/abs/1512.00567) architecture as your base model. To do that, you need to:\n\n1. Set the input shape to fit your application. In this case. set it to `150x150x3` as you've been doing in the last few labs.\n\n2. Pick and freeze the convolution layers to take advantage of the features it has learned already.\n\n3. Add dense layers which you will train.\n\nLet's see how to do these in the next cells.","metadata":{"id":"-12slkPL6_JH"}},{"cell_type":"markdown","source":"First, in preparing the input to the model, you want to fetch the pretrained weights of the `InceptionV3` model and remove the fully connected layer at the end because you will be replacing it later. You will also specify the input shape that your model will accept. Lastly, you want to freeze the weights of these layers because they have been trained already.","metadata":{"id":"3VqhFEK2Y-PK"}},{"cell_type":"code","source":"# Download the pre-trained weights. No top means it excludes the fully connected layer it uses for classification.\n!wget --no-check-certificate \\\n    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O ./venv/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5","metadata":{"id":"1xJZ5glPPCRz","execution":{"iopub.status.busy":"2024-07-26T12:18:37.572151Z","iopub.execute_input":"2024-07-26T12:18:37.572884Z","iopub.status.idle":"2024-07-26T12:18:39.323047Z","shell.execute_reply.started":"2024-07-26T12:18:37.572849Z","shell.execute_reply":"2024-07-26T12:18:39.322132Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"--2024-07-26 12:18:38--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\nResolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.207, 74.125.139.207, 108.177.11.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 87910968 (84M) [application/x-hdf]\nSaving to: './venv/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n./venv/inception_v3 100%[===================>]  83.84M   150MB/s    in 0.6s    \n\n2024-07-26 12:18:39 (150 MB/s) - './venv/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5' saved [87910968/87910968]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras import layers\n\n# Set the weights file you downloaded into a variable\nlocal_weights_file = './venv/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# Initialize the base model.\n# Set the input shape and remove the dense layers.\npre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n                                include_top = False,\n                                weights = None)\n\n# Load the pre-trained weights you downloaded.\npre_trained_model.load_weights(local_weights_file)\n\n# Freeze the weights of the layers.\nfor layer in pre_trained_model.layers:\n  layer.trainable = False","metadata":{"id":"KsiBCpQ1VvPp","execution":{"iopub.status.busy":"2024-07-26T12:19:09.010947Z","iopub.execute_input":"2024-07-26T12:19:09.011802Z","iopub.status.idle":"2024-07-26T12:19:24.107108Z","shell.execute_reply.started":"2024-07-26T12:19:09.011766Z","shell.execute_reply":"2024-07-26T12:19:24.106314Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"2024-07-26 12:19:10.681963: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-26 12:19:10.682079: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-26 12:19:10.809302: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"You can see the summary of the model below. You can see that it is a very deep network. You can then select up to which point of the network you want to use. As Laurence showed in the exercise, you will use up to `mixed7` as your base model and add to that. This is because the original last layer might be too specialized in what it has learned so it might not translate well into your application. `mixed7` on the other hand will be more generalized and you can start with that for your application. After the exercise, feel free to modify and use other layers to see what the results you get.","metadata":{"id":"1y2rEnqFaa9k"}},{"cell_type":"code","source":"pre_trained_model.summary()","metadata":{"id":"qeGP0Ust5kCR","execution":{"iopub.status.busy":"2024-07-26T12:19:34.052484Z","iopub.execute_input":"2024-07-26T12:19:34.053104Z","iopub.status.idle":"2024-07-26T12:19:34.810898Z","shell.execute_reply.started":"2024-07-26T12:19:34.053070Z","shell.execute_reply":"2024-07-26T12:19:34.809972Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"inception_v3\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 150, 150, 3)]        0         []                            \n                                                                                                  \n conv2d (Conv2D)             (None, 74, 74, 32)           864       ['input_1[0][0]']             \n                                                                                                  \n batch_normalization (Batch  (None, 74, 74, 32)           96        ['conv2d[0][0]']              \n Normalization)                                                                                   \n                                                                                                  \n activation (Activation)     (None, 74, 74, 32)           0         ['batch_normalization[0][0]'] \n                                                                                                  \n conv2d_1 (Conv2D)           (None, 72, 72, 32)           9216      ['activation[0][0]']          \n                                                                                                  \n batch_normalization_1 (Bat  (None, 72, 72, 32)           96        ['conv2d_1[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_1 (Activation)   (None, 72, 72, 32)           0         ['batch_normalization_1[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_2 (Conv2D)           (None, 72, 72, 64)           18432     ['activation_1[0][0]']        \n                                                                                                  \n batch_normalization_2 (Bat  (None, 72, 72, 64)           192       ['conv2d_2[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_2 (Activation)   (None, 72, 72, 64)           0         ['batch_normalization_2[0][0]'\n                                                                    ]                             \n                                                                                                  \n max_pooling2d (MaxPooling2  (None, 35, 35, 64)           0         ['activation_2[0][0]']        \n D)                                                                                               \n                                                                                                  \n conv2d_3 (Conv2D)           (None, 35, 35, 80)           5120      ['max_pooling2d[0][0]']       \n                                                                                                  \n batch_normalization_3 (Bat  (None, 35, 35, 80)           240       ['conv2d_3[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_3 (Activation)   (None, 35, 35, 80)           0         ['batch_normalization_3[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_4 (Conv2D)           (None, 33, 33, 192)          138240    ['activation_3[0][0]']        \n                                                                                                  \n batch_normalization_4 (Bat  (None, 33, 33, 192)          576       ['conv2d_4[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_4 (Activation)   (None, 33, 33, 192)          0         ['batch_normalization_4[0][0]'\n                                                                    ]                             \n                                                                                                  \n max_pooling2d_1 (MaxPoolin  (None, 16, 16, 192)          0         ['activation_4[0][0]']        \n g2D)                                                                                             \n                                                                                                  \n conv2d_8 (Conv2D)           (None, 16, 16, 64)           12288     ['max_pooling2d_1[0][0]']     \n                                                                                                  \n batch_normalization_8 (Bat  (None, 16, 16, 64)           192       ['conv2d_8[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_8 (Activation)   (None, 16, 16, 64)           0         ['batch_normalization_8[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_6 (Conv2D)           (None, 16, 16, 48)           9216      ['max_pooling2d_1[0][0]']     \n                                                                                                  \n conv2d_9 (Conv2D)           (None, 16, 16, 96)           55296     ['activation_8[0][0]']        \n                                                                                                  \n batch_normalization_6 (Bat  (None, 16, 16, 48)           144       ['conv2d_6[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_9 (Bat  (None, 16, 16, 96)           288       ['conv2d_9[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_6 (Activation)   (None, 16, 16, 48)           0         ['batch_normalization_6[0][0]'\n                                                                    ]                             \n                                                                                                  \n activation_9 (Activation)   (None, 16, 16, 96)           0         ['batch_normalization_9[0][0]'\n                                                                    ]                             \n                                                                                                  \n average_pooling2d (Average  (None, 16, 16, 192)          0         ['max_pooling2d_1[0][0]']     \n Pooling2D)                                                                                       \n                                                                                                  \n conv2d_5 (Conv2D)           (None, 16, 16, 64)           12288     ['max_pooling2d_1[0][0]']     \n                                                                                                  \n conv2d_7 (Conv2D)           (None, 16, 16, 64)           76800     ['activation_6[0][0]']        \n                                                                                                  \n conv2d_10 (Conv2D)          (None, 16, 16, 96)           82944     ['activation_9[0][0]']        \n                                                                                                  \n conv2d_11 (Conv2D)          (None, 16, 16, 32)           6144      ['average_pooling2d[0][0]']   \n                                                                                                  \n batch_normalization_5 (Bat  (None, 16, 16, 64)           192       ['conv2d_5[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_7 (Bat  (None, 16, 16, 64)           192       ['conv2d_7[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_10 (Ba  (None, 16, 16, 96)           288       ['conv2d_10[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_11 (Ba  (None, 16, 16, 32)           96        ['conv2d_11[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_5 (Activation)   (None, 16, 16, 64)           0         ['batch_normalization_5[0][0]'\n                                                                    ]                             \n                                                                                                  \n activation_7 (Activation)   (None, 16, 16, 64)           0         ['batch_normalization_7[0][0]'\n                                                                    ]                             \n                                                                                                  \n activation_10 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_10[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_11 (Activation)  (None, 16, 16, 32)           0         ['batch_normalization_11[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed0 (Concatenate)        (None, 16, 16, 256)          0         ['activation_5[0][0]',        \n                                                                     'activation_7[0][0]',        \n                                                                     'activation_10[0][0]',       \n                                                                     'activation_11[0][0]']       \n                                                                                                  \n conv2d_15 (Conv2D)          (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n                                                                                                  \n batch_normalization_15 (Ba  (None, 16, 16, 64)           192       ['conv2d_15[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_15 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_15[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_13 (Conv2D)          (None, 16, 16, 48)           12288     ['mixed0[0][0]']              \n                                                                                                  \n conv2d_16 (Conv2D)          (None, 16, 16, 96)           55296     ['activation_15[0][0]']       \n                                                                                                  \n batch_normalization_13 (Ba  (None, 16, 16, 48)           144       ['conv2d_13[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_16 (Ba  (None, 16, 16, 96)           288       ['conv2d_16[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_13 (Activation)  (None, 16, 16, 48)           0         ['batch_normalization_13[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_16 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_16[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_1 (Avera  (None, 16, 16, 256)          0         ['mixed0[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_12 (Conv2D)          (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n                                                                                                  \n conv2d_14 (Conv2D)          (None, 16, 16, 64)           76800     ['activation_13[0][0]']       \n                                                                                                  \n conv2d_17 (Conv2D)          (None, 16, 16, 96)           82944     ['activation_16[0][0]']       \n                                                                                                  \n conv2d_18 (Conv2D)          (None, 16, 16, 64)           16384     ['average_pooling2d_1[0][0]'] \n                                                                                                  \n batch_normalization_12 (Ba  (None, 16, 16, 64)           192       ['conv2d_12[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_14 (Ba  (None, 16, 16, 64)           192       ['conv2d_14[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_17 (Ba  (None, 16, 16, 96)           288       ['conv2d_17[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_18 (Ba  (None, 16, 16, 64)           192       ['conv2d_18[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_12 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_12[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_14 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_14[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_17 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_17[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_18 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_18[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed1 (Concatenate)        (None, 16, 16, 288)          0         ['activation_12[0][0]',       \n                                                                     'activation_14[0][0]',       \n                                                                     'activation_17[0][0]',       \n                                                                     'activation_18[0][0]']       \n                                                                                                  \n conv2d_22 (Conv2D)          (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n                                                                                                  \n batch_normalization_22 (Ba  (None, 16, 16, 64)           192       ['conv2d_22[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_22 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_22[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_20 (Conv2D)          (None, 16, 16, 48)           13824     ['mixed1[0][0]']              \n                                                                                                  \n conv2d_23 (Conv2D)          (None, 16, 16, 96)           55296     ['activation_22[0][0]']       \n                                                                                                  \n batch_normalization_20 (Ba  (None, 16, 16, 48)           144       ['conv2d_20[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_23 (Ba  (None, 16, 16, 96)           288       ['conv2d_23[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_20 (Activation)  (None, 16, 16, 48)           0         ['batch_normalization_20[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_23 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_23[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_2 (Avera  (None, 16, 16, 288)          0         ['mixed1[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_19 (Conv2D)          (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n                                                                                                  \n conv2d_21 (Conv2D)          (None, 16, 16, 64)           76800     ['activation_20[0][0]']       \n                                                                                                  \n conv2d_24 (Conv2D)          (None, 16, 16, 96)           82944     ['activation_23[0][0]']       \n                                                                                                  \n conv2d_25 (Conv2D)          (None, 16, 16, 64)           18432     ['average_pooling2d_2[0][0]'] \n                                                                                                  \n batch_normalization_19 (Ba  (None, 16, 16, 64)           192       ['conv2d_19[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_21 (Ba  (None, 16, 16, 64)           192       ['conv2d_21[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_24 (Ba  (None, 16, 16, 96)           288       ['conv2d_24[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_25 (Ba  (None, 16, 16, 64)           192       ['conv2d_25[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_19 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_19[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_21 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_21[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_24 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_24[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_25 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_25[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed2 (Concatenate)        (None, 16, 16, 288)          0         ['activation_19[0][0]',       \n                                                                     'activation_21[0][0]',       \n                                                                     'activation_24[0][0]',       \n                                                                     'activation_25[0][0]']       \n                                                                                                  \n conv2d_27 (Conv2D)          (None, 16, 16, 64)           18432     ['mixed2[0][0]']              \n                                                                                                  \n batch_normalization_27 (Ba  (None, 16, 16, 64)           192       ['conv2d_27[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_27 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_27[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_28 (Conv2D)          (None, 16, 16, 96)           55296     ['activation_27[0][0]']       \n                                                                                                  \n batch_normalization_28 (Ba  (None, 16, 16, 96)           288       ['conv2d_28[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_28 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_28[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_26 (Conv2D)          (None, 7, 7, 384)            995328    ['mixed2[0][0]']              \n                                                                                                  \n conv2d_29 (Conv2D)          (None, 7, 7, 96)             82944     ['activation_28[0][0]']       \n                                                                                                  \n batch_normalization_26 (Ba  (None, 7, 7, 384)            1152      ['conv2d_26[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_29 (Ba  (None, 7, 7, 96)             288       ['conv2d_29[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_26 (Activation)  (None, 7, 7, 384)            0         ['batch_normalization_26[0][0]\n tchNormalization)                                                                                \n                                                                                                  \n activation_26 (Activation)  (None, 7, 7, 384)            0         ['batch_normalization_26[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_29 (Activation)  (None, 7, 7, 96)             0         ['batch_normalization_29[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed3 (Concatenate)        (None, 7, 7, 768)            0         ['activation_26[0][0]',       \n                                                                     'activation_29[0][0]',       \n                                                                     'max_pooling2d_2[0][0]']     \n                                                                                                  \n conv2d_34 (Conv2D)          (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n                                                                                                  \n batch_normalization_34 (Ba  (None, 7, 7, 128)            384       ['conv2d_34[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_34 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_34[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_35 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_34[0][0]']       \n                                                                                                  \n batch_normalization_35 (Ba  (None, 7, 7, 128)            384       ['conv2d_35[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_35 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_35[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_31 (Conv2D)          (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n                                                                                                  \n conv2d_36 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_35[0][0]']       \n                                                                                                  \n batch_normalization_31 (Ba  (None, 7, 7, 128)            384       ['conv2d_31[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_36 (Ba  (None, 7, 7, 128)            384       ['conv2d_36[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_31 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_31[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_36 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_36[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_32 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_31[0][0]']       \n                                                                                                  \n conv2d_37 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_36[0][0]']       \n                                                                                                  \n batch_normalization_32 (Ba  (None, 7, 7, 128)            384       ['conv2d_32[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_37 (Ba  (None, 7, 7, 128)            384       ['conv2d_37[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_32 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_32[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_37 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_37[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_3 (Avera  (None, 7, 7, 768)            0         ['mixed3[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_30 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed3[0][0]']              \n                                                                                                  \n conv2d_33 (Conv2D)          (None, 7, 7, 192)            172032    ['activation_32[0][0]']       \n                                                                                                  \n conv2d_38 (Conv2D)          (None, 7, 7, 192)            172032    ['activation_37[0][0]']       \n                                                                                                  \n conv2d_39 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_3[0][0]'] \n                                                                                                  \n batch_normalization_30 (Ba  (None, 7, 7, 192)            576       ['conv2d_30[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_33 (Ba  (None, 7, 7, 192)            576       ['conv2d_33[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_38 (Ba  (None, 7, 7, 192)            576       ['conv2d_38[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_39 (Ba  (None, 7, 7, 192)            576       ['conv2d_39[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_30 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_30[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_33 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_33[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_38 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_38[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_39 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_39[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed4 (Concatenate)        (None, 7, 7, 768)            0         ['activation_30[0][0]',       \n                                                                     'activation_33[0][0]',       \n                                                                     'activation_38[0][0]',       \n                                                                     'activation_39[0][0]']       \n                                                                                                  \n conv2d_44 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n                                                                                                  \n batch_normalization_44 (Ba  (None, 7, 7, 160)            480       ['conv2d_44[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_44 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_44[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_45 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_44[0][0]']       \n                                                                                                  \n batch_normalization_45 (Ba  (None, 7, 7, 160)            480       ['conv2d_45[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_45 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_45[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_41 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n                                                                                                  \n conv2d_46 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_45[0][0]']       \n                                                                                                  \n batch_normalization_41 (Ba  (None, 7, 7, 160)            480       ['conv2d_41[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_46 (Ba  (None, 7, 7, 160)            480       ['conv2d_46[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_41 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_41[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_46 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_46[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_42 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_41[0][0]']       \n                                                                                                  \n conv2d_47 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_46[0][0]']       \n                                                                                                  \n batch_normalization_42 (Ba  (None, 7, 7, 160)            480       ['conv2d_42[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_47 (Ba  (None, 7, 7, 160)            480       ['conv2d_47[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_42 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_42[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_47 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_47[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_4 (Avera  (None, 7, 7, 768)            0         ['mixed4[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_40 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed4[0][0]']              \n                                                                                                  \n conv2d_43 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_42[0][0]']       \n                                                                                                  \n conv2d_48 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_47[0][0]']       \n                                                                                                  \n conv2d_49 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_4[0][0]'] \n                                                                                                  \n batch_normalization_40 (Ba  (None, 7, 7, 192)            576       ['conv2d_40[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_43 (Ba  (None, 7, 7, 192)            576       ['conv2d_43[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_48 (Ba  (None, 7, 7, 192)            576       ['conv2d_48[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_49 (Ba  (None, 7, 7, 192)            576       ['conv2d_49[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_40 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_40[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_43 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_43[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_48 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_48[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_49 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_49[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed5 (Concatenate)        (None, 7, 7, 768)            0         ['activation_40[0][0]',       \n                                                                     'activation_43[0][0]',       \n                                                                     'activation_48[0][0]',       \n                                                                     'activation_49[0][0]']       \n                                                                                                  \n conv2d_54 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n                                                                                                  \n batch_normalization_54 (Ba  (None, 7, 7, 160)            480       ['conv2d_54[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_54 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_54[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_55 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_54[0][0]']       \n                                                                                                  \n batch_normalization_55 (Ba  (None, 7, 7, 160)            480       ['conv2d_55[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_55 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_55[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_51 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n                                                                                                  \n conv2d_56 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_55[0][0]']       \n                                                                                                  \n batch_normalization_51 (Ba  (None, 7, 7, 160)            480       ['conv2d_51[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_56 (Ba  (None, 7, 7, 160)            480       ['conv2d_56[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_51 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_51[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_56 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_56[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_52 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_51[0][0]']       \n                                                                                                  \n conv2d_57 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_56[0][0]']       \n                                                                                                  \n batch_normalization_52 (Ba  (None, 7, 7, 160)            480       ['conv2d_52[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_57 (Ba  (None, 7, 7, 160)            480       ['conv2d_57[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_52 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_52[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_57 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_57[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_5 (Avera  (None, 7, 7, 768)            0         ['mixed5[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_50 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed5[0][0]']              \n                                                                                                  \n conv2d_53 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_52[0][0]']       \n                                                                                                  \n conv2d_58 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_57[0][0]']       \n                                                                                                  \n conv2d_59 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_5[0][0]'] \n                                                                                                  \n batch_normalization_50 (Ba  (None, 7, 7, 192)            576       ['conv2d_50[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_53 (Ba  (None, 7, 7, 192)            576       ['conv2d_53[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_58 (Ba  (None, 7, 7, 192)            576       ['conv2d_58[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_59 (Ba  (None, 7, 7, 192)            576       ['conv2d_59[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_50 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_50[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_53 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_53[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_58 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_58[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_59 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_59[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed6 (Concatenate)        (None, 7, 7, 768)            0         ['activation_50[0][0]',       \n                                                                     'activation_53[0][0]',       \n                                                                     'activation_58[0][0]',       \n                                                                     'activation_59[0][0]']       \n                                                                                                  \n conv2d_64 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n                                                                                                  \n batch_normalization_64 (Ba  (None, 7, 7, 192)            576       ['conv2d_64[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_64 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_64[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_65 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_64[0][0]']       \n                                                                                                  \n batch_normalization_65 (Ba  (None, 7, 7, 192)            576       ['conv2d_65[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_65 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_65[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_61 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n                                                                                                  \n conv2d_66 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_65[0][0]']       \n                                                                                                  \n batch_normalization_61 (Ba  (None, 7, 7, 192)            576       ['conv2d_61[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_66 (Ba  (None, 7, 7, 192)            576       ['conv2d_66[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_61 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_61[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_66 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_66[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_62 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_61[0][0]']       \n                                                                                                  \n conv2d_67 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_66[0][0]']       \n                                                                                                  \n batch_normalization_62 (Ba  (None, 7, 7, 192)            576       ['conv2d_62[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_67 (Ba  (None, 7, 7, 192)            576       ['conv2d_67[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_62 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_62[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_67 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_67[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_6 (Avera  (None, 7, 7, 768)            0         ['mixed6[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_60 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n                                                                                                  \n conv2d_63 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_62[0][0]']       \n                                                                                                  \n conv2d_68 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_67[0][0]']       \n                                                                                                  \n conv2d_69 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_6[0][0]'] \n                                                                                                  \n batch_normalization_60 (Ba  (None, 7, 7, 192)            576       ['conv2d_60[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_63 (Ba  (None, 7, 7, 192)            576       ['conv2d_63[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_68 (Ba  (None, 7, 7, 192)            576       ['conv2d_68[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_69 (Ba  (None, 7, 7, 192)            576       ['conv2d_69[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_60 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_60[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_63 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_63[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_68 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_68[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_69 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_69[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed7 (Concatenate)        (None, 7, 7, 768)            0         ['activation_60[0][0]',       \n                                                                     'activation_63[0][0]',       \n                                                                     'activation_68[0][0]',       \n                                                                     'activation_69[0][0]']       \n                                                                                                  \n conv2d_72 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed7[0][0]']              \n                                                                                                  \n batch_normalization_72 (Ba  (None, 7, 7, 192)            576       ['conv2d_72[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_72 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_72[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_73 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_72[0][0]']       \n                                                                                                  \n batch_normalization_73 (Ba  (None, 7, 7, 192)            576       ['conv2d_73[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_73 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_73[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_70 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed7[0][0]']              \n                                                                                                  \n conv2d_74 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_73[0][0]']       \n                                                                                                  \n batch_normalization_70 (Ba  (None, 7, 7, 192)            576       ['conv2d_70[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_74 (Ba  (None, 7, 7, 192)            576       ['conv2d_74[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_70 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_70[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_74 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_74[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_71 (Conv2D)          (None, 3, 3, 320)            552960    ['activation_70[0][0]']       \n                                                                                                  \n conv2d_75 (Conv2D)          (None, 3, 3, 192)            331776    ['activation_74[0][0]']       \n                                                                                                  \n batch_normalization_71 (Ba  (None, 3, 3, 320)            960       ['conv2d_71[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_75 (Ba  (None, 3, 3, 192)            576       ['conv2d_75[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_71 (Activation)  (None, 3, 3, 320)            0         ['batch_normalization_71[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_75 (Activation)  (None, 3, 3, 192)            0         ['batch_normalization_75[0][0]\n                                                                    ']                            \n                                                                                                  \n max_pooling2d_3 (MaxPoolin  (None, 3, 3, 768)            0         ['mixed7[0][0]']              \n g2D)                                                                                             \n                                                                                                  \n mixed8 (Concatenate)        (None, 3, 3, 1280)           0         ['activation_71[0][0]',       \n                                                                     'activation_75[0][0]',       \n                                                                     'max_pooling2d_3[0][0]']     \n                                                                                                  \n conv2d_80 (Conv2D)          (None, 3, 3, 448)            573440    ['mixed8[0][0]']              \n                                                                                                  \n batch_normalization_80 (Ba  (None, 3, 3, 448)            1344      ['conv2d_80[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_80 (Activation)  (None, 3, 3, 448)            0         ['batch_normalization_80[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_77 (Conv2D)          (None, 3, 3, 384)            491520    ['mixed8[0][0]']              \n                                                                                                  \n conv2d_81 (Conv2D)          (None, 3, 3, 384)            1548288   ['activation_80[0][0]']       \n                                                                                                  \n batch_normalization_77 (Ba  (None, 3, 3, 384)            1152      ['conv2d_77[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_81 (Ba  (None, 3, 3, 384)            1152      ['conv2d_81[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_77 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_77[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_81 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_81[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_78 (Conv2D)          (None, 3, 3, 384)            442368    ['activation_77[0][0]']       \n                                                                                                  \n conv2d_79 (Conv2D)          (None, 3, 3, 384)            442368    ['activation_77[0][0]']       \n                                                                                                  \n conv2d_82 (Conv2D)          (None, 3, 3, 384)            442368    ['activation_81[0][0]']       \n                                                                                                  \n conv2d_83 (Conv2D)          (None, 3, 3, 384)            442368    ['activation_81[0][0]']       \n                                                                                                  \n average_pooling2d_7 (Avera  (None, 3, 3, 1280)           0         ['mixed8[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_76 (Conv2D)          (None, 3, 3, 320)            409600    ['mixed8[0][0]']              \n                                                                                                  \n batch_normalization_78 (Ba  (None, 3, 3, 384)            1152      ['conv2d_78[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_79 (Ba  (None, 3, 3, 384)            1152      ['conv2d_79[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_82 (Ba  (None, 3, 3, 384)            1152      ['conv2d_82[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_83 (Ba  (None, 3, 3, 384)            1152      ['conv2d_83[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n conv2d_84 (Conv2D)          (None, 3, 3, 192)            245760    ['average_pooling2d_7[0][0]'] \n                                                                                                  \n batch_normalization_76 (Ba  (None, 3, 3, 320)            960       ['conv2d_76[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_78 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_78[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_79 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_79[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_82 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_82[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_83 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_83[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_84 (Ba  (None, 3, 3, 192)            576       ['conv2d_84[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_76 (Activation)  (None, 3, 3, 320)            0         ['batch_normalization_76[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed9_0 (Concatenate)      (None, 3, 3, 768)            0         ['activation_78[0][0]',       \n                                                                     'activation_79[0][0]']       \n                                                                                                  \n concatenate (Concatenate)   (None, 3, 3, 768)            0         ['activation_82[0][0]',       \n                                                                     'activation_83[0][0]']       \n                                                                                                  \n activation_84 (Activation)  (None, 3, 3, 192)            0         ['batch_normalization_84[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed9 (Concatenate)        (None, 3, 3, 2048)           0         ['activation_76[0][0]',       \n                                                                     'mixed9_0[0][0]',            \n                                                                     'concatenate[0][0]',         \n                                                                     'activation_84[0][0]']       \n                                                                                                  \n conv2d_89 (Conv2D)          (None, 3, 3, 448)            917504    ['mixed9[0][0]']              \n                                                                                                  \n batch_normalization_89 (Ba  (None, 3, 3, 448)            1344      ['conv2d_89[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_89 (Activation)  (None, 3, 3, 448)            0         ['batch_normalization_89[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_86 (Conv2D)          (None, 3, 3, 384)            786432    ['mixed9[0][0]']              \n                                                                                                  \n conv2d_90 (Conv2D)          (None, 3, 3, 384)            1548288   ['activation_89[0][0]']       \n                                                                                                  \n batch_normalization_86 (Ba  (None, 3, 3, 384)            1152      ['conv2d_86[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_90 (Ba  (None, 3, 3, 384)            1152      ['conv2d_90[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_86 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_86[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_90 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_90[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_87 (Conv2D)          (None, 3, 3, 384)            442368    ['activation_86[0][0]']       \n                                                                                                  \n conv2d_88 (Conv2D)          (None, 3, 3, 384)            442368    ['activation_86[0][0]']       \n                                                                                                  \n conv2d_91 (Conv2D)          (None, 3, 3, 384)            442368    ['activation_90[0][0]']       \n                                                                                                  \n conv2d_92 (Conv2D)          (None, 3, 3, 384)            442368    ['activation_90[0][0]']       \n                                                                                                  \n average_pooling2d_8 (Avera  (None, 3, 3, 2048)           0         ['mixed9[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_85 (Conv2D)          (None, 3, 3, 320)            655360    ['mixed9[0][0]']              \n                                                                                                  \n batch_normalization_87 (Ba  (None, 3, 3, 384)            1152      ['conv2d_87[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_88 (Ba  (None, 3, 3, 384)            1152      ['conv2d_88[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_91 (Ba  (None, 3, 3, 384)            1152      ['conv2d_91[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_92 (Ba  (None, 3, 3, 384)            1152      ['conv2d_92[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n conv2d_93 (Conv2D)          (None, 3, 3, 192)            393216    ['average_pooling2d_8[0][0]'] \n                                                                                                  \n batch_normalization_85 (Ba  (None, 3, 3, 320)            960       ['conv2d_85[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_87 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_87[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_88 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_88[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_91 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_91[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_92 (Activation)  (None, 3, 3, 384)            0         ['batch_normalization_92[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_93 (Ba  (None, 3, 3, 192)            576       ['conv2d_93[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_85 (Activation)  (None, 3, 3, 320)            0         ['batch_normalization_85[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed9_1 (Concatenate)      (None, 3, 3, 768)            0         ['activation_87[0][0]',       \n                                                                     'activation_88[0][0]']       \n                                                                                                  \n concatenate_1 (Concatenate  (None, 3, 3, 768)            0         ['activation_91[0][0]',       \n )                                                                   'activation_92[0][0]']       \n                                                                                                  \n activation_93 (Activation)  (None, 3, 3, 192)            0         ['batch_normalization_93[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed10 (Concatenate)       (None, 3, 3, 2048)           0         ['activation_85[0][0]',       \n                                                                     'mixed9_1[0][0]',            \n                                                                     'concatenate_1[0][0]',       \n                                                                     'activation_93[0][0]']       \n                                                                                                  \n==================================================================================================\nTotal params: 21802784 (83.17 MB)\nTrainable params: 0 (0.00 Byte)\nNon-trainable params: 21802784 (83.17 MB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Choose `mixed7` as the last layer of your base model\nlast_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","metadata":{"id":"jDmGO9tg5iPc","execution":{"iopub.status.busy":"2024-07-26T12:19:53.103079Z","iopub.execute_input":"2024-07-26T12:19:53.103760Z","iopub.status.idle":"2024-07-26T12:19:53.109954Z","shell.execute_reply.started":"2024-07-26T12:19:53.103731Z","shell.execute_reply":"2024-07-26T12:19:53.108852Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"last layer output shape:  (None, 7, 7, 768)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Add dense layers for your classifier\n\nNext, you will add dense layers to your model. These will be the layers that you will train and is tasked with recognizing cats and dogs. You will add a [Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layer as well to regularize the output and avoid overfitting.","metadata":{"id":"UXT9SDMK7Ioa"}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras import Model\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)\n# Add a final sigmoid layer for classification\nx = layers.Dense  (1, activation='sigmoid')(x)\n\n# Append the dense network to the base model\nmodel = Model(pre_trained_model.input, x)\n\n# Print the model summary. See your dense network connected at the end.\nmodel.summary()","metadata":{"id":"BMXb913pbvFg","execution":{"iopub.status.busy":"2024-07-26T12:20:03.549469Z","iopub.execute_input":"2024-07-26T12:20:03.549851Z","iopub.status.idle":"2024-07-26T12:20:04.172674Z","shell.execute_reply.started":"2024-07-26T12:20:03.549822Z","shell.execute_reply":"2024-07-26T12:20:04.171712Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 150, 150, 3)]        0         []                            \n                                                                                                  \n conv2d (Conv2D)             (None, 74, 74, 32)           864       ['input_1[0][0]']             \n                                                                                                  \n batch_normalization (Batch  (None, 74, 74, 32)           96        ['conv2d[0][0]']              \n Normalization)                                                                                   \n                                                                                                  \n activation (Activation)     (None, 74, 74, 32)           0         ['batch_normalization[0][0]'] \n                                                                                                  \n conv2d_1 (Conv2D)           (None, 72, 72, 32)           9216      ['activation[0][0]']          \n                                                                                                  \n batch_normalization_1 (Bat  (None, 72, 72, 32)           96        ['conv2d_1[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_1 (Activation)   (None, 72, 72, 32)           0         ['batch_normalization_1[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_2 (Conv2D)           (None, 72, 72, 64)           18432     ['activation_1[0][0]']        \n                                                                                                  \n batch_normalization_2 (Bat  (None, 72, 72, 64)           192       ['conv2d_2[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_2 (Activation)   (None, 72, 72, 64)           0         ['batch_normalization_2[0][0]'\n                                                                    ]                             \n                                                                                                  \n max_pooling2d (MaxPooling2  (None, 35, 35, 64)           0         ['activation_2[0][0]']        \n D)                                                                                               \n                                                                                                  \n conv2d_3 (Conv2D)           (None, 35, 35, 80)           5120      ['max_pooling2d[0][0]']       \n                                                                                                  \n batch_normalization_3 (Bat  (None, 35, 35, 80)           240       ['conv2d_3[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_3 (Activation)   (None, 35, 35, 80)           0         ['batch_normalization_3[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_4 (Conv2D)           (None, 33, 33, 192)          138240    ['activation_3[0][0]']        \n                                                                                                  \n batch_normalization_4 (Bat  (None, 33, 33, 192)          576       ['conv2d_4[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_4 (Activation)   (None, 33, 33, 192)          0         ['batch_normalization_4[0][0]'\n                                                                    ]                             \n                                                                                                  \n max_pooling2d_1 (MaxPoolin  (None, 16, 16, 192)          0         ['activation_4[0][0]']        \n g2D)                                                                                             \n                                                                                                  \n conv2d_8 (Conv2D)           (None, 16, 16, 64)           12288     ['max_pooling2d_1[0][0]']     \n                                                                                                  \n batch_normalization_8 (Bat  (None, 16, 16, 64)           192       ['conv2d_8[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_8 (Activation)   (None, 16, 16, 64)           0         ['batch_normalization_8[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_6 (Conv2D)           (None, 16, 16, 48)           9216      ['max_pooling2d_1[0][0]']     \n                                                                                                  \n conv2d_9 (Conv2D)           (None, 16, 16, 96)           55296     ['activation_8[0][0]']        \n                                                                                                  \n batch_normalization_6 (Bat  (None, 16, 16, 48)           144       ['conv2d_6[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_9 (Bat  (None, 16, 16, 96)           288       ['conv2d_9[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_6 (Activation)   (None, 16, 16, 48)           0         ['batch_normalization_6[0][0]'\n                                                                    ]                             \n                                                                                                  \n activation_9 (Activation)   (None, 16, 16, 96)           0         ['batch_normalization_9[0][0]'\n                                                                    ]                             \n                                                                                                  \n average_pooling2d (Average  (None, 16, 16, 192)          0         ['max_pooling2d_1[0][0]']     \n Pooling2D)                                                                                       \n                                                                                                  \n conv2d_5 (Conv2D)           (None, 16, 16, 64)           12288     ['max_pooling2d_1[0][0]']     \n                                                                                                  \n conv2d_7 (Conv2D)           (None, 16, 16, 64)           76800     ['activation_6[0][0]']        \n                                                                                                  \n conv2d_10 (Conv2D)          (None, 16, 16, 96)           82944     ['activation_9[0][0]']        \n                                                                                                  \n conv2d_11 (Conv2D)          (None, 16, 16, 32)           6144      ['average_pooling2d[0][0]']   \n                                                                                                  \n batch_normalization_5 (Bat  (None, 16, 16, 64)           192       ['conv2d_5[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_7 (Bat  (None, 16, 16, 64)           192       ['conv2d_7[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_10 (Ba  (None, 16, 16, 96)           288       ['conv2d_10[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_11 (Ba  (None, 16, 16, 32)           96        ['conv2d_11[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_5 (Activation)   (None, 16, 16, 64)           0         ['batch_normalization_5[0][0]'\n                                                                    ]                             \n                                                                                                  \n activation_7 (Activation)   (None, 16, 16, 64)           0         ['batch_normalization_7[0][0]'\n                                                                    ]                             \n                                                                                                  \n activation_10 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_10[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_11 (Activation)  (None, 16, 16, 32)           0         ['batch_normalization_11[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed0 (Concatenate)        (None, 16, 16, 256)          0         ['activation_5[0][0]',        \n                                                                     'activation_7[0][0]',        \n                                                                     'activation_10[0][0]',       \n                                                                     'activation_11[0][0]']       \n                                                                                                  \n conv2d_15 (Conv2D)          (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n                                                                                                  \n batch_normalization_15 (Ba  (None, 16, 16, 64)           192       ['conv2d_15[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_15 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_15[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_13 (Conv2D)          (None, 16, 16, 48)           12288     ['mixed0[0][0]']              \n                                                                                                  \n conv2d_16 (Conv2D)          (None, 16, 16, 96)           55296     ['activation_15[0][0]']       \n                                                                                                  \n batch_normalization_13 (Ba  (None, 16, 16, 48)           144       ['conv2d_13[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_16 (Ba  (None, 16, 16, 96)           288       ['conv2d_16[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_13 (Activation)  (None, 16, 16, 48)           0         ['batch_normalization_13[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_16 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_16[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_1 (Avera  (None, 16, 16, 256)          0         ['mixed0[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_12 (Conv2D)          (None, 16, 16, 64)           16384     ['mixed0[0][0]']              \n                                                                                                  \n conv2d_14 (Conv2D)          (None, 16, 16, 64)           76800     ['activation_13[0][0]']       \n                                                                                                  \n conv2d_17 (Conv2D)          (None, 16, 16, 96)           82944     ['activation_16[0][0]']       \n                                                                                                  \n conv2d_18 (Conv2D)          (None, 16, 16, 64)           16384     ['average_pooling2d_1[0][0]'] \n                                                                                                  \n batch_normalization_12 (Ba  (None, 16, 16, 64)           192       ['conv2d_12[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_14 (Ba  (None, 16, 16, 64)           192       ['conv2d_14[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_17 (Ba  (None, 16, 16, 96)           288       ['conv2d_17[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_18 (Ba  (None, 16, 16, 64)           192       ['conv2d_18[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_12 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_12[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_14 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_14[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_17 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_17[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_18 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_18[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed1 (Concatenate)        (None, 16, 16, 288)          0         ['activation_12[0][0]',       \n                                                                     'activation_14[0][0]',       \n                                                                     'activation_17[0][0]',       \n                                                                     'activation_18[0][0]']       \n                                                                                                  \n conv2d_22 (Conv2D)          (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n                                                                                                  \n batch_normalization_22 (Ba  (None, 16, 16, 64)           192       ['conv2d_22[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_22 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_22[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_20 (Conv2D)          (None, 16, 16, 48)           13824     ['mixed1[0][0]']              \n                                                                                                  \n conv2d_23 (Conv2D)          (None, 16, 16, 96)           55296     ['activation_22[0][0]']       \n                                                                                                  \n batch_normalization_20 (Ba  (None, 16, 16, 48)           144       ['conv2d_20[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_23 (Ba  (None, 16, 16, 96)           288       ['conv2d_23[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_20 (Activation)  (None, 16, 16, 48)           0         ['batch_normalization_20[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_23 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_23[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_2 (Avera  (None, 16, 16, 288)          0         ['mixed1[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_19 (Conv2D)          (None, 16, 16, 64)           18432     ['mixed1[0][0]']              \n                                                                                                  \n conv2d_21 (Conv2D)          (None, 16, 16, 64)           76800     ['activation_20[0][0]']       \n                                                                                                  \n conv2d_24 (Conv2D)          (None, 16, 16, 96)           82944     ['activation_23[0][0]']       \n                                                                                                  \n conv2d_25 (Conv2D)          (None, 16, 16, 64)           18432     ['average_pooling2d_2[0][0]'] \n                                                                                                  \n batch_normalization_19 (Ba  (None, 16, 16, 64)           192       ['conv2d_19[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_21 (Ba  (None, 16, 16, 64)           192       ['conv2d_21[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_24 (Ba  (None, 16, 16, 96)           288       ['conv2d_24[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_25 (Ba  (None, 16, 16, 64)           192       ['conv2d_25[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_19 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_19[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_21 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_21[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_24 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_24[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_25 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_25[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed2 (Concatenate)        (None, 16, 16, 288)          0         ['activation_19[0][0]',       \n                                                                     'activation_21[0][0]',       \n                                                                     'activation_24[0][0]',       \n                                                                     'activation_25[0][0]']       \n                                                                                                  \n conv2d_27 (Conv2D)          (None, 16, 16, 64)           18432     ['mixed2[0][0]']              \n                                                                                                  \n batch_normalization_27 (Ba  (None, 16, 16, 64)           192       ['conv2d_27[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_27 (Activation)  (None, 16, 16, 64)           0         ['batch_normalization_27[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_28 (Conv2D)          (None, 16, 16, 96)           55296     ['activation_27[0][0]']       \n                                                                                                  \n batch_normalization_28 (Ba  (None, 16, 16, 96)           288       ['conv2d_28[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_28 (Activation)  (None, 16, 16, 96)           0         ['batch_normalization_28[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_26 (Conv2D)          (None, 7, 7, 384)            995328    ['mixed2[0][0]']              \n                                                                                                  \n conv2d_29 (Conv2D)          (None, 7, 7, 96)             82944     ['activation_28[0][0]']       \n                                                                                                  \n batch_normalization_26 (Ba  (None, 7, 7, 384)            1152      ['conv2d_26[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_29 (Ba  (None, 7, 7, 96)             288       ['conv2d_29[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_26 (Activation)  (None, 7, 7, 384)            0         ['batch_normalization_26[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_29 (Activation)  (None, 7, 7, 96)             0         ['batch_normalization_29[0][0]\n                                                                    ']                            \n                                                                                                  \n max_pooling2d_2 (MaxPoolin  (None, 7, 7, 288)            0         ['mixed2[0][0]']              \n g2D)                                                                                             \n                                                                                                  \n mixed3 (Concatenate)        (None, 7, 7, 768)            0         ['activation_26[0][0]',       \n                                                                     'activation_29[0][0]',       \n                                                                     'max_pooling2d_2[0][0]']     \n                                                                                                  \n conv2d_34 (Conv2D)          (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n                                                                                                  \n batch_normalization_34 (Ba  (None, 7, 7, 128)            384       ['conv2d_34[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_34 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_34[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_35 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_34[0][0]']       \n                                                                                                  \n batch_normalization_35 (Ba  (None, 7, 7, 128)            384       ['conv2d_35[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_35 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_35[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_31 (Conv2D)          (None, 7, 7, 128)            98304     ['mixed3[0][0]']              \n                                                                                                  \n conv2d_36 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_35[0][0]']       \n                                                                                                  \n batch_normalization_31 (Ba  (None, 7, 7, 128)            384       ['conv2d_31[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_36 (Ba  (None, 7, 7, 128)            384       ['conv2d_36[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_31 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_31[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_36 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_36[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_32 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_31[0][0]']       \n                                                                                                  \n conv2d_37 (Conv2D)          (None, 7, 7, 128)            114688    ['activation_36[0][0]']       \n                                                                                                  \n batch_normalization_32 (Ba  (None, 7, 7, 128)            384       ['conv2d_32[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_37 (Ba  (None, 7, 7, 128)            384       ['conv2d_37[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_32 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_32[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_37 (Activation)  (None, 7, 7, 128)            0         ['batch_normalization_37[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_3 (Avera  (None, 7, 7, 768)            0         ['mixed3[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_30 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed3[0][0]']              \n                                                                                                  \n conv2d_33 (Conv2D)          (None, 7, 7, 192)            172032    ['activation_32[0][0]']       \n                                                                                                  \n conv2d_38 (Conv2D)          (None, 7, 7, 192)            172032    ['activation_37[0][0]']       \n                                                                                                  \n conv2d_39 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_3[0][0]'] \n                                                                                                  \n batch_normalization_30 (Ba  (None, 7, 7, 192)            576       ['conv2d_30[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_33 (Ba  (None, 7, 7, 192)            576       ['conv2d_33[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_38 (Ba  (None, 7, 7, 192)            576       ['conv2d_38[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_39 (Ba  (None, 7, 7, 192)            576       ['conv2d_39[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_30 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_30[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_33 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_33[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_38 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_38[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_39 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_39[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed4 (Concatenate)        (None, 7, 7, 768)            0         ['activation_30[0][0]',       \n                                                                     'activation_33[0][0]',       \n                                                                     'activation_38[0][0]',       \n                                                                     'activation_39[0][0]']       \n                                                                                                  \n conv2d_44 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n                                                                                                  \n batch_normalization_44 (Ba  (None, 7, 7, 160)            480       ['conv2d_44[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_44 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_44[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_45 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_44[0][0]']       \n                                                                                                  \n batch_normalization_45 (Ba  (None, 7, 7, 160)            480       ['conv2d_45[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_45 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_45[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_41 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed4[0][0]']              \n                                                                                                  \n conv2d_46 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_45[0][0]']       \n                                                                                                  \n batch_normalization_41 (Ba  (None, 7, 7, 160)            480       ['conv2d_41[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_46 (Ba  (None, 7, 7, 160)            480       ['conv2d_46[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_41 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_41[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_46 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_46[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_42 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_41[0][0]']       \n                                                                                                  \n conv2d_47 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_46[0][0]']       \n                                                                                                  \n batch_normalization_42 (Ba  (None, 7, 7, 160)            480       ['conv2d_42[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_47 (Ba  (None, 7, 7, 160)            480       ['conv2d_47[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_42 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_42[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_47 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_47[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_4 (Avera  (None, 7, 7, 768)            0         ['mixed4[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_40 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed4[0][0]']              \n                                                                                                  \n conv2d_43 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_42[0][0]']       \n                                                                                                  \n conv2d_48 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_47[0][0]']       \n                                                                                                  \n conv2d_49 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_4[0][0]'] \n                                                                                                  \n batch_normalization_40 (Ba  (None, 7, 7, 192)            576       ['conv2d_40[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_43 (Ba  (None, 7, 7, 192)            576       ['conv2d_43[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_48 (Ba  (None, 7, 7, 192)            576       ['conv2d_48[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_49 (Ba  (None, 7, 7, 192)            576       ['conv2d_49[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_40 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_40[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_43 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_43[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_48 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_48[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_49 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_49[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed5 (Concatenate)        (None, 7, 7, 768)            0         ['activation_40[0][0]',       \n                                                                     'activation_43[0][0]',       \n                                                                     'activation_48[0][0]',       \n                                                                     'activation_49[0][0]']       \n                                                                                                  \n conv2d_54 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n                                                                                                  \n batch_normalization_54 (Ba  (None, 7, 7, 160)            480       ['conv2d_54[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_54 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_54[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_55 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_54[0][0]']       \n                                                                                                  \n batch_normalization_55 (Ba  (None, 7, 7, 160)            480       ['conv2d_55[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_55 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_55[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_51 (Conv2D)          (None, 7, 7, 160)            122880    ['mixed5[0][0]']              \n                                                                                                  \n conv2d_56 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_55[0][0]']       \n                                                                                                  \n batch_normalization_51 (Ba  (None, 7, 7, 160)            480       ['conv2d_51[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_56 (Ba  (None, 7, 7, 160)            480       ['conv2d_56[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_51 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_51[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_56 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_56[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_52 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_51[0][0]']       \n                                                                                                  \n conv2d_57 (Conv2D)          (None, 7, 7, 160)            179200    ['activation_56[0][0]']       \n                                                                                                  \n batch_normalization_52 (Ba  (None, 7, 7, 160)            480       ['conv2d_52[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_57 (Ba  (None, 7, 7, 160)            480       ['conv2d_57[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_52 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_52[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_57 (Activation)  (None, 7, 7, 160)            0         ['batch_normalization_57[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_5 (Avera  (None, 7, 7, 768)            0         ['mixed5[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_50 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed5[0][0]']              \n                                                                                                  \n conv2d_53 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_52[0][0]']       \n                                                                                                  \n conv2d_58 (Conv2D)          (None, 7, 7, 192)            215040    ['activation_57[0][0]']       \n                                                                                                  \n conv2d_59 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_5[0][0]'] \n                                                                                                  \n batch_normalization_50 (Ba  (None, 7, 7, 192)            576       ['conv2d_50[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_53 (Ba  (None, 7, 7, 192)            576       ['conv2d_53[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_58 (Ba  (None, 7, 7, 192)            576       ['conv2d_58[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_59 (Ba  (None, 7, 7, 192)            576       ['conv2d_59[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_50 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_50[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_53 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_53[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_58 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_58[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_59 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_59[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed6 (Concatenate)        (None, 7, 7, 768)            0         ['activation_50[0][0]',       \n                                                                     'activation_53[0][0]',       \n                                                                     'activation_58[0][0]',       \n                                                                     'activation_59[0][0]']       \n                                                                                                  \n conv2d_64 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n                                                                                                  \n batch_normalization_64 (Ba  (None, 7, 7, 192)            576       ['conv2d_64[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_64 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_64[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_65 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_64[0][0]']       \n                                                                                                  \n batch_normalization_65 (Ba  (None, 7, 7, 192)            576       ['conv2d_65[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_65 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_65[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_61 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n                                                                                                  \n conv2d_66 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_65[0][0]']       \n                                                                                                  \n batch_normalization_61 (Ba  (None, 7, 7, 192)            576       ['conv2d_61[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_66 (Ba  (None, 7, 7, 192)            576       ['conv2d_66[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_61 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_61[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_66 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_66[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_62 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_61[0][0]']       \n                                                                                                  \n conv2d_67 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_66[0][0]']       \n                                                                                                  \n batch_normalization_62 (Ba  (None, 7, 7, 192)            576       ['conv2d_62[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_67 (Ba  (None, 7, 7, 192)            576       ['conv2d_67[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_62 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_62[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_67 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_67[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_6 (Avera  (None, 7, 7, 768)            0         ['mixed6[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_60 (Conv2D)          (None, 7, 7, 192)            147456    ['mixed6[0][0]']              \n                                                                                                  \n conv2d_63 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_62[0][0]']       \n                                                                                                  \n conv2d_68 (Conv2D)          (None, 7, 7, 192)            258048    ['activation_67[0][0]']       \n                                                                                                  \n conv2d_69 (Conv2D)          (None, 7, 7, 192)            147456    ['average_pooling2d_6[0][0]'] \n                                                                                                  \n batch_normalization_60 (Ba  (None, 7, 7, 192)            576       ['conv2d_60[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_63 (Ba  (None, 7, 7, 192)            576       ['conv2d_63[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_68 (Ba  (None, 7, 7, 192)            576       ['conv2d_68[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_69 (Ba  (None, 7, 7, 192)            576       ['conv2d_69[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_60 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_60[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_63 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_63[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_68 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_68[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_69 (Activation)  (None, 7, 7, 192)            0         ['batch_normalization_69[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed7 (Concatenate)        (None, 7, 7, 768)            0         ['activation_60[0][0]',       \n                                                                     'activation_63[0][0]',       \n                                                                     'activation_68[0][0]',       \n                                                                     'activation_69[0][0]']       \n                                                                                                  \n flatten (Flatten)           (None, 37632)                0         ['mixed7[0][0]']              \n                                                                                                  \n dense (Dense)               (None, 1024)                 3853619   ['flatten[0][0]']             \n                                                          2                                       \n                                                                                                  \n dropout (Dropout)           (None, 1024)                 0         ['dense[0][0]']               \n                                                                                                  \n dense_1 (Dense)             (None, 1)                    1025      ['dropout[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 47512481 (181.25 MB)\nTrainable params: 38537217 (147.01 MB)\nNon-trainable params: 8975264 (34.24 MB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the training parameters\nmodel.compile(optimizer = RMSprop(learning_rate=0.0001),\n              loss = 'binary_crossentropy',\n              metrics = ['accuracy'])","metadata":{"id":"SAwTTkWr56uC","execution":{"iopub.status.busy":"2024-07-26T12:20:39.053285Z","iopub.execute_input":"2024-07-26T12:20:39.054030Z","iopub.status.idle":"2024-07-26T12:20:39.078907Z","shell.execute_reply.started":"2024-07-26T12:20:39.053996Z","shell.execute_reply":"2024-07-26T12:20:39.077971Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Prepare the dataset\n\nNow you will prepare the dataset. This is basically the same code as the one you used in the data augmentation lab.","metadata":{"id":"aYLGw_RO7Z_X"}},{"cell_type":"code","source":"# Download the dataset\n!wget https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip -O \"./venv/cats_and_dogs_filtered.zip\"","metadata":{"id":"O4s8HckqGlnb","execution":{"iopub.status.busy":"2024-07-26T12:21:41.400149Z","iopub.execute_input":"2024-07-26T12:21:41.400561Z","iopub.status.idle":"2024-07-26T12:21:43.093844Z","shell.execute_reply.started":"2024-07-26T12:21:41.400522Z","shell.execute_reply":"2024-07-26T12:21:43.092737Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"--2024-07-26 12:21:42--  https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip\nResolving storage.googleapis.com (storage.googleapis.com)... 173.194.212.207, 172.217.203.207, 74.125.196.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|173.194.212.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 68606236 (65M) [application/zip]\nSaving to: './venv/cats_and_dogs_filtered.zip'\n\n./venv/cats_and_dog 100%[===================>]  65.43M   150MB/s    in 0.4s    \n\n2024-07-26 12:21:42 (150 MB/s) - './venv/cats_and_dogs_filtered.zip' saved [68606236/68606236]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport zipfile\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Extract the archive\nzip_ref = zipfile.ZipFile(\"./venv/cats_and_dogs_filtered.zip\", 'r')\nzip_ref.extractall(\"./venv/\")\nzip_ref.close()\n\n# Define our example directories and files\nbase_dir = './venv/cats_and_dogs_filtered'\n\ntrain_dir = os.path.join( base_dir, 'train')\nvalidation_dir = os.path.join( base_dir, 'validation')\n\n# Directory with training cat pictures\ntrain_cats_dir = os.path.join(train_dir, 'cats')\n\n# Directory with training dog pictures\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\n\n# Directory with validation cat pictures\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\n\n# Directory with validation dog pictures\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')\n\n# Add our data-augmentation parameters to ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale = 1./255.,\n                                   rotation_range = 40,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\n# Note that the validation data should not be augmented!\ntest_datagen = ImageDataGenerator( rescale = 1.0/255. )\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size = 20,\n                                                    class_mode = 'binary',\n                                                    target_size = (150, 150))\n\n# Flow validation images in batches of 20 using test_datagen generator\nvalidation_generator =  test_datagen.flow_from_directory( validation_dir,\n                                                          batch_size  = 20,\n                                                          class_mode  = 'binary',\n                                                          target_size = (150, 150))","metadata":{"id":"WOV8jON3c3Jv","execution":{"iopub.status.busy":"2024-07-26T12:22:30.709328Z","iopub.execute_input":"2024-07-26T12:22:30.710287Z","iopub.status.idle":"2024-07-26T12:22:31.743879Z","shell.execute_reply.started":"2024-07-26T12:22:30.710236Z","shell.execute_reply":"2024-07-26T12:22:31.742813Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Found 2000 images belonging to 2 classes.\nFound 1000 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train the model\n\nWith that, you can now train the model. You will do 20 epochs and plot the results afterwards.","metadata":{"id":"3m3S6AZb7h-B"}},{"cell_type":"code","source":"# Train the model.\nhistory = model.fit(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 20,\n            validation_steps = 50,\n            verbose = 2)","metadata":{"id":"Blhq2MAUeyGA","execution":{"iopub.status.busy":"2024-07-26T12:22:45.652532Z","iopub.execute_input":"2024-07-26T12:22:45.653340Z","iopub.status.idle":"2024-07-26T12:28:19.503202Z","shell.execute_reply.started":"2024-07-26T12:22:45.653302Z","shell.execute_reply":"2024-07-26T12:28:19.502111Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1721996574.107155     144 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"100/100 - 25s - loss: 0.3353 - accuracy: 0.8630 - val_loss: 0.1097 - val_accuracy: 0.9580 - 25s/epoch - 252ms/step\nEpoch 2/20\n100/100 - 16s - loss: 0.2123 - accuracy: 0.9140 - val_loss: 0.0869 - val_accuracy: 0.9630 - 16s/epoch - 163ms/step\nEpoch 3/20\n100/100 - 16s - loss: 0.1913 - accuracy: 0.9220 - val_loss: 0.1193 - val_accuracy: 0.9580 - 16s/epoch - 160ms/step\nEpoch 4/20\n100/100 - 17s - loss: 0.1761 - accuracy: 0.9365 - val_loss: 0.0816 - val_accuracy: 0.9730 - 17s/epoch - 165ms/step\nEpoch 5/20\n100/100 - 16s - loss: 0.1861 - accuracy: 0.9260 - val_loss: 0.1343 - val_accuracy: 0.9490 - 16s/epoch - 162ms/step\nEpoch 6/20\n100/100 - 16s - loss: 0.1650 - accuracy: 0.9365 - val_loss: 0.1032 - val_accuracy: 0.9580 - 16s/epoch - 161ms/step\nEpoch 7/20\n100/100 - 16s - loss: 0.1607 - accuracy: 0.9380 - val_loss: 0.0861 - val_accuracy: 0.9670 - 16s/epoch - 161ms/step\nEpoch 8/20\n100/100 - 16s - loss: 0.1261 - accuracy: 0.9510 - val_loss: 0.0857 - val_accuracy: 0.9680 - 16s/epoch - 161ms/step\nEpoch 9/20\n100/100 - 16s - loss: 0.1349 - accuracy: 0.9485 - val_loss: 0.1327 - val_accuracy: 0.9590 - 16s/epoch - 162ms/step\nEpoch 10/20\n100/100 - 16s - loss: 0.1376 - accuracy: 0.9530 - val_loss: 0.1046 - val_accuracy: 0.9580 - 16s/epoch - 160ms/step\nEpoch 11/20\n100/100 - 16s - loss: 0.1363 - accuracy: 0.9495 - val_loss: 0.1256 - val_accuracy: 0.9510 - 16s/epoch - 162ms/step\nEpoch 12/20\n100/100 - 17s - loss: 0.1231 - accuracy: 0.9540 - val_loss: 0.0898 - val_accuracy: 0.9660 - 17s/epoch - 170ms/step\nEpoch 13/20\n100/100 - 16s - loss: 0.1290 - accuracy: 0.9515 - val_loss: 0.0807 - val_accuracy: 0.9730 - 16s/epoch - 162ms/step\nEpoch 14/20\n100/100 - 16s - loss: 0.1328 - accuracy: 0.9440 - val_loss: 0.0861 - val_accuracy: 0.9710 - 16s/epoch - 162ms/step\nEpoch 15/20\n100/100 - 16s - loss: 0.1386 - accuracy: 0.9465 - val_loss: 0.1033 - val_accuracy: 0.9630 - 16s/epoch - 162ms/step\nEpoch 16/20\n100/100 - 16s - loss: 0.1152 - accuracy: 0.9555 - val_loss: 0.0906 - val_accuracy: 0.9720 - 16s/epoch - 163ms/step\nEpoch 17/20\n100/100 - 16s - loss: 0.1278 - accuracy: 0.9530 - val_loss: 0.0727 - val_accuracy: 0.9720 - 16s/epoch - 162ms/step\nEpoch 18/20\n100/100 - 16s - loss: 0.1101 - accuracy: 0.9585 - val_loss: 0.1048 - val_accuracy: 0.9640 - 16s/epoch - 160ms/step\nEpoch 19/20\n100/100 - 16s - loss: 0.1053 - accuracy: 0.9610 - val_loss: 0.0937 - val_accuracy: 0.9710 - 16s/epoch - 159ms/step\nEpoch 20/20\n100/100 - 16s - loss: 0.1036 - accuracy: 0.9570 - val_loss: 0.1746 - val_accuracy: 0.9470 - 16s/epoch - 163ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model.\nhistory = model.fit(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 100,\n            validation_steps = 50,\n            verbose = 2)","metadata":{"execution":{"iopub.status.busy":"2024-07-26T12:39:19.438437Z","iopub.execute_input":"2024-07-26T12:39:19.439640Z","iopub.status.idle":"2024-07-26T13:06:15.315714Z","shell.execute_reply.started":"2024-07-26T12:39:19.439596Z","shell.execute_reply":"2024-07-26T13:06:15.314601Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/100\n100/100 - 16s - loss: 0.1013 - accuracy: 0.9610 - val_loss: 0.0904 - val_accuracy: 0.9690 - 16s/epoch - 163ms/step\nEpoch 2/100\n100/100 - 16s - loss: 0.0831 - accuracy: 0.9700 - val_loss: 0.0908 - val_accuracy: 0.9730 - 16s/epoch - 162ms/step\nEpoch 3/100\n100/100 - 16s - loss: 0.0950 - accuracy: 0.9600 - val_loss: 0.1366 - val_accuracy: 0.9530 - 16s/epoch - 164ms/step\nEpoch 4/100\n100/100 - 17s - loss: 0.1034 - accuracy: 0.9575 - val_loss: 0.0888 - val_accuracy: 0.9700 - 17s/epoch - 166ms/step\nEpoch 5/100\n100/100 - 16s - loss: 0.0911 - accuracy: 0.9615 - val_loss: 0.0953 - val_accuracy: 0.9680 - 16s/epoch - 164ms/step\nEpoch 6/100\n100/100 - 16s - loss: 0.0869 - accuracy: 0.9640 - val_loss: 0.1049 - val_accuracy: 0.9710 - 16s/epoch - 165ms/step\nEpoch 7/100\n100/100 - 16s - loss: 0.1041 - accuracy: 0.9620 - val_loss: 0.0864 - val_accuracy: 0.9710 - 16s/epoch - 165ms/step\nEpoch 8/100\n100/100 - 16s - loss: 0.0922 - accuracy: 0.9655 - val_loss: 0.0781 - val_accuracy: 0.9730 - 16s/epoch - 164ms/step\nEpoch 9/100\n100/100 - 17s - loss: 0.0991 - accuracy: 0.9615 - val_loss: 0.1016 - val_accuracy: 0.9620 - 17s/epoch - 166ms/step\nEpoch 10/100\n100/100 - 16s - loss: 0.0944 - accuracy: 0.9605 - val_loss: 0.0772 - val_accuracy: 0.9740 - 16s/epoch - 162ms/step\nEpoch 11/100\n100/100 - 17s - loss: 0.0892 - accuracy: 0.9725 - val_loss: 0.0899 - val_accuracy: 0.9710 - 17s/epoch - 165ms/step\nEpoch 12/100\n100/100 - 16s - loss: 0.0876 - accuracy: 0.9700 - val_loss: 0.0918 - val_accuracy: 0.9690 - 16s/epoch - 162ms/step\nEpoch 13/100\n100/100 - 16s - loss: 0.0785 - accuracy: 0.9675 - val_loss: 0.1208 - val_accuracy: 0.9610 - 16s/epoch - 164ms/step\nEpoch 14/100\n100/100 - 16s - loss: 0.0886 - accuracy: 0.9625 - val_loss: 0.0992 - val_accuracy: 0.9690 - 16s/epoch - 163ms/step\nEpoch 15/100\n100/100 - 16s - loss: 0.0887 - accuracy: 0.9710 - val_loss: 0.1014 - val_accuracy: 0.9690 - 16s/epoch - 162ms/step\nEpoch 16/100\n100/100 - 16s - loss: 0.0731 - accuracy: 0.9710 - val_loss: 0.0887 - val_accuracy: 0.9710 - 16s/epoch - 162ms/step\nEpoch 17/100\n100/100 - 17s - loss: 0.0853 - accuracy: 0.9730 - val_loss: 0.0965 - val_accuracy: 0.9690 - 17s/epoch - 166ms/step\nEpoch 18/100\n100/100 - 16s - loss: 0.0780 - accuracy: 0.9750 - val_loss: 0.0929 - val_accuracy: 0.9710 - 16s/epoch - 162ms/step\nEpoch 19/100\n100/100 - 16s - loss: 0.0857 - accuracy: 0.9690 - val_loss: 0.0767 - val_accuracy: 0.9760 - 16s/epoch - 164ms/step\nEpoch 20/100\n100/100 - 16s - loss: 0.0628 - accuracy: 0.9750 - val_loss: 0.0971 - val_accuracy: 0.9700 - 16s/epoch - 162ms/step\nEpoch 21/100\n100/100 - 16s - loss: 0.0723 - accuracy: 0.9760 - val_loss: 0.1120 - val_accuracy: 0.9630 - 16s/epoch - 162ms/step\nEpoch 22/100\n100/100 - 16s - loss: 0.0858 - accuracy: 0.9655 - val_loss: 0.1047 - val_accuracy: 0.9670 - 16s/epoch - 162ms/step\nEpoch 23/100\n100/100 - 16s - loss: 0.0663 - accuracy: 0.9740 - val_loss: 0.0902 - val_accuracy: 0.9750 - 16s/epoch - 163ms/step\nEpoch 24/100\n100/100 - 16s - loss: 0.0617 - accuracy: 0.9785 - val_loss: 0.1039 - val_accuracy: 0.9710 - 16s/epoch - 161ms/step\nEpoch 25/100\n100/100 - 16s - loss: 0.0681 - accuracy: 0.9800 - val_loss: 0.0884 - val_accuracy: 0.9760 - 16s/epoch - 162ms/step\nEpoch 26/100\n100/100 - 16s - loss: 0.0588 - accuracy: 0.9800 - val_loss: 0.1083 - val_accuracy: 0.9720 - 16s/epoch - 162ms/step\nEpoch 27/100\n100/100 - 16s - loss: 0.0729 - accuracy: 0.9740 - val_loss: 0.1046 - val_accuracy: 0.9740 - 16s/epoch - 161ms/step\nEpoch 28/100\n100/100 - 16s - loss: 0.0846 - accuracy: 0.9705 - val_loss: 0.1048 - val_accuracy: 0.9700 - 16s/epoch - 163ms/step\nEpoch 29/100\n100/100 - 16s - loss: 0.0880 - accuracy: 0.9700 - val_loss: 0.0766 - val_accuracy: 0.9760 - 16s/epoch - 163ms/step\nEpoch 30/100\n100/100 - 16s - loss: 0.0741 - accuracy: 0.9705 - val_loss: 0.0951 - val_accuracy: 0.9710 - 16s/epoch - 163ms/step\nEpoch 31/100\n100/100 - 16s - loss: 0.0740 - accuracy: 0.9735 - val_loss: 0.1093 - val_accuracy: 0.9670 - 16s/epoch - 162ms/step\nEpoch 32/100\n100/100 - 16s - loss: 0.0682 - accuracy: 0.9775 - val_loss: 0.0851 - val_accuracy: 0.9740 - 16s/epoch - 163ms/step\nEpoch 33/100\n100/100 - 16s - loss: 0.0644 - accuracy: 0.9720 - val_loss: 0.0979 - val_accuracy: 0.9660 - 16s/epoch - 161ms/step\nEpoch 34/100\n100/100 - 16s - loss: 0.0660 - accuracy: 0.9770 - val_loss: 0.0818 - val_accuracy: 0.9760 - 16s/epoch - 164ms/step\nEpoch 35/100\n100/100 - 16s - loss: 0.0719 - accuracy: 0.9735 - val_loss: 0.0943 - val_accuracy: 0.9710 - 16s/epoch - 161ms/step\nEpoch 36/100\n100/100 - 16s - loss: 0.0657 - accuracy: 0.9740 - val_loss: 0.1176 - val_accuracy: 0.9620 - 16s/epoch - 163ms/step\nEpoch 37/100\n100/100 - 16s - loss: 0.0687 - accuracy: 0.9800 - val_loss: 0.1021 - val_accuracy: 0.9710 - 16s/epoch - 163ms/step\nEpoch 38/100\n100/100 - 16s - loss: 0.0578 - accuracy: 0.9785 - val_loss: 0.1105 - val_accuracy: 0.9630 - 16s/epoch - 162ms/step\nEpoch 39/100\n100/100 - 16s - loss: 0.0556 - accuracy: 0.9765 - val_loss: 0.0901 - val_accuracy: 0.9730 - 16s/epoch - 161ms/step\nEpoch 40/100\n100/100 - 16s - loss: 0.0565 - accuracy: 0.9835 - val_loss: 0.1018 - val_accuracy: 0.9750 - 16s/epoch - 162ms/step\nEpoch 41/100\n100/100 - 16s - loss: 0.0653 - accuracy: 0.9735 - val_loss: 0.0752 - val_accuracy: 0.9740 - 16s/epoch - 160ms/step\nEpoch 42/100\n100/100 - 16s - loss: 0.0625 - accuracy: 0.9785 - val_loss: 0.0678 - val_accuracy: 0.9730 - 16s/epoch - 162ms/step\nEpoch 43/100\n100/100 - 16s - loss: 0.0452 - accuracy: 0.9815 - val_loss: 0.0906 - val_accuracy: 0.9710 - 16s/epoch - 161ms/step\nEpoch 44/100\n100/100 - 16s - loss: 0.0556 - accuracy: 0.9795 - val_loss: 0.1163 - val_accuracy: 0.9660 - 16s/epoch - 163ms/step\nEpoch 45/100\n100/100 - 16s - loss: 0.0655 - accuracy: 0.9775 - val_loss: 0.0932 - val_accuracy: 0.9690 - 16s/epoch - 162ms/step\nEpoch 46/100\n100/100 - 16s - loss: 0.0483 - accuracy: 0.9815 - val_loss: 0.0949 - val_accuracy: 0.9710 - 16s/epoch - 165ms/step\nEpoch 47/100\n100/100 - 16s - loss: 0.0581 - accuracy: 0.9770 - val_loss: 0.1072 - val_accuracy: 0.9670 - 16s/epoch - 163ms/step\nEpoch 48/100\n100/100 - 16s - loss: 0.0457 - accuracy: 0.9820 - val_loss: 0.1091 - val_accuracy: 0.9630 - 16s/epoch - 161ms/step\nEpoch 49/100\n100/100 - 16s - loss: 0.0488 - accuracy: 0.9840 - val_loss: 0.1137 - val_accuracy: 0.9650 - 16s/epoch - 159ms/step\nEpoch 50/100\n100/100 - 16s - loss: 0.0432 - accuracy: 0.9820 - val_loss: 0.0943 - val_accuracy: 0.9750 - 16s/epoch - 159ms/step\nEpoch 51/100\n100/100 - 16s - loss: 0.0610 - accuracy: 0.9805 - val_loss: 0.1240 - val_accuracy: 0.9610 - 16s/epoch - 159ms/step\nEpoch 52/100\n100/100 - 16s - loss: 0.0441 - accuracy: 0.9825 - val_loss: 0.1059 - val_accuracy: 0.9750 - 16s/epoch - 161ms/step\nEpoch 53/100\n100/100 - 16s - loss: 0.0522 - accuracy: 0.9780 - val_loss: 0.1175 - val_accuracy: 0.9670 - 16s/epoch - 159ms/step\nEpoch 54/100\n100/100 - 16s - loss: 0.0491 - accuracy: 0.9800 - val_loss: 0.2005 - val_accuracy: 0.9440 - 16s/epoch - 159ms/step\nEpoch 55/100\n100/100 - 16s - loss: 0.0504 - accuracy: 0.9820 - val_loss: 0.0942 - val_accuracy: 0.9700 - 16s/epoch - 158ms/step\nEpoch 56/100\n100/100 - 16s - loss: 0.0480 - accuracy: 0.9840 - val_loss: 0.1145 - val_accuracy: 0.9640 - 16s/epoch - 161ms/step\nEpoch 57/100\n100/100 - 16s - loss: 0.0518 - accuracy: 0.9835 - val_loss: 0.1150 - val_accuracy: 0.9650 - 16s/epoch - 159ms/step\nEpoch 58/100\n100/100 - 16s - loss: 0.0699 - accuracy: 0.9730 - val_loss: 0.1292 - val_accuracy: 0.9590 - 16s/epoch - 157ms/step\nEpoch 59/100\n100/100 - 16s - loss: 0.0499 - accuracy: 0.9815 - val_loss: 0.1079 - val_accuracy: 0.9740 - 16s/epoch - 158ms/step\nEpoch 60/100\n100/100 - 16s - loss: 0.0477 - accuracy: 0.9835 - val_loss: 0.1019 - val_accuracy: 0.9670 - 16s/epoch - 158ms/step\nEpoch 61/100\n100/100 - 16s - loss: 0.0418 - accuracy: 0.9850 - val_loss: 0.1137 - val_accuracy: 0.9710 - 16s/epoch - 159ms/step\nEpoch 62/100\n100/100 - 17s - loss: 0.0458 - accuracy: 0.9830 - val_loss: 0.1118 - val_accuracy: 0.9690 - 17s/epoch - 167ms/step\nEpoch 63/100\n100/100 - 16s - loss: 0.0437 - accuracy: 0.9815 - val_loss: 0.1165 - val_accuracy: 0.9650 - 16s/epoch - 159ms/step\nEpoch 64/100\n100/100 - 16s - loss: 0.0540 - accuracy: 0.9785 - val_loss: 0.1016 - val_accuracy: 0.9680 - 16s/epoch - 158ms/step\nEpoch 65/100\n100/100 - 16s - loss: 0.0403 - accuracy: 0.9835 - val_loss: 0.1135 - val_accuracy: 0.9700 - 16s/epoch - 159ms/step\nEpoch 66/100\n100/100 - 16s - loss: 0.0413 - accuracy: 0.9850 - val_loss: 0.1298 - val_accuracy: 0.9620 - 16s/epoch - 158ms/step\nEpoch 67/100\n100/100 - 16s - loss: 0.0397 - accuracy: 0.9885 - val_loss: 0.1111 - val_accuracy: 0.9680 - 16s/epoch - 158ms/step\nEpoch 68/100\n100/100 - 16s - loss: 0.0528 - accuracy: 0.9800 - val_loss: 0.1020 - val_accuracy: 0.9670 - 16s/epoch - 158ms/step\nEpoch 69/100\n100/100 - 16s - loss: 0.0455 - accuracy: 0.9815 - val_loss: 0.1500 - val_accuracy: 0.9580 - 16s/epoch - 159ms/step\nEpoch 70/100\n100/100 - 16s - loss: 0.0596 - accuracy: 0.9775 - val_loss: 0.0862 - val_accuracy: 0.9760 - 16s/epoch - 157ms/step\nEpoch 71/100\n100/100 - 16s - loss: 0.0474 - accuracy: 0.9840 - val_loss: 0.1068 - val_accuracy: 0.9660 - 16s/epoch - 160ms/step\nEpoch 72/100\n100/100 - 16s - loss: 0.0404 - accuracy: 0.9845 - val_loss: 0.1069 - val_accuracy: 0.9680 - 16s/epoch - 155ms/step\nEpoch 73/100\n100/100 - 16s - loss: 0.0466 - accuracy: 0.9835 - val_loss: 0.1255 - val_accuracy: 0.9590 - 16s/epoch - 157ms/step\nEpoch 74/100\n100/100 - 16s - loss: 0.0400 - accuracy: 0.9860 - val_loss: 0.0960 - val_accuracy: 0.9740 - 16s/epoch - 158ms/step\nEpoch 75/100\n100/100 - 16s - loss: 0.0526 - accuracy: 0.9835 - val_loss: 0.1122 - val_accuracy: 0.9620 - 16s/epoch - 162ms/step\nEpoch 76/100\n100/100 - 16s - loss: 0.0360 - accuracy: 0.9860 - val_loss: 0.0935 - val_accuracy: 0.9660 - 16s/epoch - 159ms/step\nEpoch 77/100\n100/100 - 16s - loss: 0.0428 - accuracy: 0.9850 - val_loss: 0.0963 - val_accuracy: 0.9660 - 16s/epoch - 160ms/step\nEpoch 78/100\n100/100 - 16s - loss: 0.0363 - accuracy: 0.9850 - val_loss: 0.0962 - val_accuracy: 0.9690 - 16s/epoch - 159ms/step\nEpoch 79/100\n100/100 - 16s - loss: 0.0379 - accuracy: 0.9860 - val_loss: 0.1189 - val_accuracy: 0.9670 - 16s/epoch - 159ms/step\nEpoch 80/100\n100/100 - 16s - loss: 0.0333 - accuracy: 0.9850 - val_loss: 0.1146 - val_accuracy: 0.9680 - 16s/epoch - 158ms/step\nEpoch 81/100\n100/100 - 16s - loss: 0.0336 - accuracy: 0.9900 - val_loss: 0.1071 - val_accuracy: 0.9730 - 16s/epoch - 160ms/step\nEpoch 82/100\n100/100 - 16s - loss: 0.0499 - accuracy: 0.9805 - val_loss: 0.1085 - val_accuracy: 0.9680 - 16s/epoch - 159ms/step\nEpoch 83/100\n100/100 - 16s - loss: 0.0424 - accuracy: 0.9860 - val_loss: 0.0918 - val_accuracy: 0.9680 - 16s/epoch - 159ms/step\nEpoch 84/100\n100/100 - 16s - loss: 0.0485 - accuracy: 0.9835 - val_loss: 0.1054 - val_accuracy: 0.9670 - 16s/epoch - 159ms/step\nEpoch 85/100\n100/100 - 16s - loss: 0.0334 - accuracy: 0.9890 - val_loss: 0.1117 - val_accuracy: 0.9680 - 16s/epoch - 158ms/step\nEpoch 86/100\n100/100 - 16s - loss: 0.0348 - accuracy: 0.9875 - val_loss: 0.1338 - val_accuracy: 0.9620 - 16s/epoch - 160ms/step\nEpoch 87/100\n100/100 - 16s - loss: 0.0388 - accuracy: 0.9850 - val_loss: 0.1031 - val_accuracy: 0.9730 - 16s/epoch - 160ms/step\nEpoch 88/100\n100/100 - 16s - loss: 0.0349 - accuracy: 0.9870 - val_loss: 0.1134 - val_accuracy: 0.9720 - 16s/epoch - 157ms/step\nEpoch 89/100\n100/100 - 16s - loss: 0.0278 - accuracy: 0.9885 - val_loss: 0.1251 - val_accuracy: 0.9660 - 16s/epoch - 160ms/step\nEpoch 90/100\n100/100 - 16s - loss: 0.0383 - accuracy: 0.9850 - val_loss: 0.1195 - val_accuracy: 0.9670 - 16s/epoch - 158ms/step\nEpoch 91/100\n100/100 - 16s - loss: 0.0359 - accuracy: 0.9860 - val_loss: 0.1038 - val_accuracy: 0.9710 - 16s/epoch - 159ms/step\nEpoch 92/100\n100/100 - 16s - loss: 0.0417 - accuracy: 0.9865 - val_loss: 0.1076 - val_accuracy: 0.9690 - 16s/epoch - 157ms/step\nEpoch 93/100\n100/100 - 16s - loss: 0.0384 - accuracy: 0.9855 - val_loss: 0.0931 - val_accuracy: 0.9710 - 16s/epoch - 164ms/step\nEpoch 94/100\n100/100 - 17s - loss: 0.0291 - accuracy: 0.9870 - val_loss: 0.1154 - val_accuracy: 0.9630 - 17s/epoch - 169ms/step\nEpoch 95/100\n100/100 - 17s - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.0894 - val_accuracy: 0.9700 - 17s/epoch - 172ms/step\nEpoch 96/100\n100/100 - 17s - loss: 0.0444 - accuracy: 0.9825 - val_loss: 0.0872 - val_accuracy: 0.9760 - 17s/epoch - 168ms/step\nEpoch 97/100\n100/100 - 17s - loss: 0.0260 - accuracy: 0.9885 - val_loss: 0.0956 - val_accuracy: 0.9660 - 17s/epoch - 167ms/step\nEpoch 98/100\n100/100 - 17s - loss: 0.0323 - accuracy: 0.9890 - val_loss: 0.1084 - val_accuracy: 0.9640 - 17s/epoch - 166ms/step\nEpoch 99/100\n100/100 - 17s - loss: 0.0325 - accuracy: 0.9895 - val_loss: 0.0963 - val_accuracy: 0.9720 - 17s/epoch - 166ms/step\nEpoch 100/100\n100/100 - 17s - loss: 0.0414 - accuracy: 0.9850 - val_loss: 0.0977 - val_accuracy: 0.9720 - 17s/epoch - 166ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluate the results\n\nYou will use the same code to plot the results. As you can see, the validation accuracy is also trending upwards as your training accuracy improves. This is a good sign that your model is no longer overfitting!","metadata":{"id":"RwcB2bPj7lIx"}},{"cell_type":"markdown","source":"epochs = 20","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\n\nplt.show()","metadata":{"id":"C2Fp6Se9rKuL","execution":{"iopub.status.busy":"2024-07-26T12:28:19.505089Z","iopub.execute_input":"2024-07-26T12:28:19.505424Z","iopub.status.idle":"2024-07-26T12:28:19.832557Z","shell.execute_reply.started":"2024-07-26T12:28:19.505394Z","shell.execute_reply":"2024-07-26T12:28:19.831462Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 0 Axes>"},"metadata":{}}]},{"cell_type":"markdown","source":"epochs = 100","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-26T13:06:15.317566Z","iopub.execute_input":"2024-07-26T13:06:15.317886Z","iopub.status.idle":"2024-07-26T13:06:15.626683Z","shell.execute_reply.started":"2024-07-26T13:06:15.317858Z","shell.execute_reply":"2024-07-26T13:06:15.625797Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 0 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}